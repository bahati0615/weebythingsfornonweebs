{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8QRrhMnjKoH"
   },
   "source": [
    "From the 3 CSV files, we will begin cleaing and filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "_BzZFlG_ioBA",
    "outputId": "4f2552f1-ceea-471b-c2d3-462c8c3c9283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime_df Shape: (12716, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "anime_id        0\n",
       "title           0\n",
       "status          0\n",
       "aired_string    0\n",
       "score           0\n",
       "scored_by       0\n",
       "rank            0\n",
       "popularity      0\n",
       "members         0\n",
       "genre           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# assign csv data urls\n",
    "# anime_data    = 'https://f000.backblazeb2.com/file/mal-db/AnimeList.csv'\n",
    "# user_data     = 'https://f000.backblazeb2.com/file/mal-db/UserList.csv'\n",
    "# user_mal_data = 'https://f000.backblazeb2.com/file/mal-db/UserAnimeList.csv'\n",
    "\n",
    "# local directory\n",
    "anime_data    = 'C:\\\\Users\\\\Uri\\\\Desktop\\\\data\\\\AnimeList.csv'\n",
    "user_data     = 'C:\\\\Users\\\\Uri\\\\Desktop\\\\data\\\\UserList.csv'\n",
    "#user_mal_data = 'C:\\\\Users\\\\Uri\\\\Desktop\\\\data\\\\UserAnimeList.csv'\n",
    "\n",
    "# set maximum number of rows to 20 & define NaN identifiers\n",
    "pd.set_option('max_rows', 20)\n",
    "idntfrs = ['na', '-', '--', '?', 'None', 'none', 'non', '', ' ', \\\n",
    "           'Not available', '0']\n",
    "\n",
    "# define chunk size for user_mal_data since the file is too large\n",
    "# my_chunk = 10**4\n",
    "\n",
    "# read & import data into pandas data frames\n",
    "anime_df    = pd.read_csv(anime_data, na_values=idntfrs)\n",
    "user_df     = pd.read_csv(user_data, na_values=idntfrs)\n",
    "#user_mal_df = pd.read_csv(user_mal_data, na_values=idntfrs)\n",
    "\n",
    "# since UserAnimeList.csv is too large, read it from a generator in chunks\n",
    "# user_mal_gen = pd.read_csv(user_mal_data, na_values=idntfrs, iterator=True, \\\n",
    "#                            chunksize = my_chunk)\n",
    "# user_mal_df  = next(user_mal_gen)\n",
    "\n",
    "# display shape and rows of each data frame\n",
    "# print('anime_df Shape:', anime_df.shape)\n",
    "# anime_df.head()\n",
    "\n",
    "# print('user_df Shape:', user_df.shape)\n",
    "# user_df.head()\n",
    "\n",
    "# print('user_mal_df Shape:', user_mal_df.shape)\n",
    "# user_mal_df.head()\n",
    "\n",
    "# drop unwanted features from the anime data frame\n",
    "anime_df.drop(['title_english', 'title_japanese', 'title_synonyms', \\\n",
    " \t\t\t   'image_url', 'type', 'source', 'episodes', 'airing', 'aired', \\\n",
    " \t\t\t   'duration', 'rating', 'broadcast', 'related', \\\n",
    " \t\t\t   'producer', 'licensor', 'premiered', 'studio', 'opening_theme', \\\n",
    " \t\t\t   'ending_theme', 'background', 'favorites'],\n",
    "               axis=1, inplace=True)\n",
    "\n",
    "anime_df.dropna(inplace=True)\n",
    "\n",
    "# fix broken apostrophes across the entire dataframe\n",
    "# anime_df.replace('&#039;', '\\'', inplace=True)\n",
    "anime_df['title'] = anime_df['title'].str.replace('&#039;', '\\'')\n",
    "\n",
    "# remove animes that have not yet aired since they don't have scoring data\n",
    "# anime_df = anime_df[~anime_df['status'].isin(['Not yet aired'])]\n",
    "\n",
    "# remove NSFW content\n",
    "# anime_df = anime_df[~anime_df['genre'].astype(str).str.contains('Hentai')]\n",
    "\n",
    "# convert genres to a list\n",
    "# anime_df['genre'] = anime_df.genre.str.split(',')\n",
    "\n",
    "# write cleaned data frame to csv file\n",
    "anime_df.to_csv('anime.csv', index=False) \n",
    "print('anime_df Shape:', anime_df.shape)\n",
    "anime_df.head()\n",
    "anime_df.isna().sum()\n",
    "\n",
    "# drop unwanted features from the user data frame\n",
    "# user_df.drop(['user_watching', 'user_completed', 'user_onhold', \\\n",
    "#               'user_dropped', 'user_plantowatch', 'user_days_spent_watching'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "anime_recommender.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ECE143",
   "language": "python",
   "name": "ece143"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
