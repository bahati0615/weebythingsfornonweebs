{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8QRrhMnjKoH"
   },
   "source": [
    "From the 3 CSV files, we will begin cleaing and filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "_BzZFlG_ioBA",
    "outputId": "4f2552f1-ceea-471b-c2d3-462c8c3c9283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tokyo' 'jakarta' 'delhi' ... 'cheremoshna' 'ambarchik' 'nordvik']\n",
      "cities_df Shape: (26569, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tokyo</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jakarta</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>delhi</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mumbai</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>manila</td>\n",
       "      <td>Philippines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city      country\n",
       "0    tokyo        Japan\n",
       "1  jakarta    Indonesia\n",
       "2    delhi        India\n",
       "3   mumbai        India\n",
       "4   manila  Philippines"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import geonamescache\n",
    "from collections import defaultdict\n",
    "\n",
    "# function definitions\n",
    "def calculate_age(born):\n",
    "    born = datetime.strptime(born, '%Y-%m-%d').date()\n",
    "    today = date.today()\n",
    "    if (today.month, today.year) < (born.month, born.year):\n",
    "        age = (today.year - born.year) - 1\n",
    "    else:\n",
    "        age = today.year - born.year\n",
    "        \n",
    "    return age\n",
    "\n",
    "# assign csv data urls\n",
    "# anime_data    = 'https://f000.backblazeb2.com/file/mal-db/AnimeList.csv'\n",
    "# user_data     = 'https://f000.backblazeb2.com/file/mal-db/UserList.csv'\n",
    "# user_mal_data = 'https://f000.backblazeb2.com/file/mal-db/UserAnimeList.csv'\n",
    "\n",
    "# local directory\n",
    "anime_data    = 'C:\\\\Users\\\\Uri\\\\Desktop\\\\data\\\\AnimeList.csv'\n",
    "user_data     = 'C:\\\\Users\\\\Uri\\\\Desktop\\\\data\\\\UserList.csv'\n",
    "user_mal_data = 'C:\\\\Users\\\\Uri\\\\Desktop\\\\data\\\\UserAnimeList.csv'\n",
    "\n",
    "cities = 'worldcities.csv'\n",
    "\n",
    "# set maximum number of rows to 20 & define NaN identifiers\n",
    "pd.set_option('max_rows', 20)\n",
    "idntfrs = ['na', '-', '--', '?', 'None', 'none', 'non', '', ' ', \\\n",
    "           'Not available', '0']\n",
    "\n",
    "# read & import data into pandas data frames\n",
    "anime_df    = pd.read_csv(anime_data, na_values=idntfrs)\n",
    "user_df     = pd.read_csv(user_data, na_values=idntfrs)\n",
    "cities_df   = pd.read_csv(cities)\n",
    "\n",
    "# my_reader = pd.read_csv(user_mal_data, chunksize=my_chunk, iterator=True)\n",
    "# user_mal_df = pd.concat(my_reader, ignore_index=True)\n",
    "\n",
    "# since UserAnimeList.csv is too large, read it from a generator in chunks\n",
    "# user_mal_gen = pd.read_csv(user_mal_data, na_values=idntfrs, iterator=True, \\\n",
    "#                            chunksize = my_chunk)\n",
    "# user_mal_df  = next(user_mal_gen)\n",
    "\n",
    "# display shape and rows of each data frame\n",
    "# print('anime_df Shape:', anime_df.shape)\n",
    "# anime_df.head()\n",
    "\n",
    "# print('user_df Shape:', user_df.shape)\n",
    "# user_df.head()\n",
    "\n",
    "# print('user_mal_df Shape:', user_mal_df.shape)\n",
    "# user_mal_df.head()\n",
    "\n",
    "# drop unwanted features from the data frames\n",
    "anime_df.drop(['title_english', 'title_japanese', 'title_synonyms', \\\n",
    " \t\t\t   'image_url', 'type', 'source', 'episodes', 'airing', 'aired', \\\n",
    " \t\t\t   'duration', 'rating', 'broadcast', 'related', \\\n",
    " \t\t\t   'producer', 'licensor', 'premiered', 'studio', 'opening_theme', \\\n",
    " \t\t\t   'ending_theme', 'background', 'favorites'],\n",
    "               axis=1, inplace=True)\n",
    "\n",
    "user_df.drop(['user_watching', 'user_completed', 'user_onhold', 'user_dropped', \\\n",
    "              'user_plantowatch', 'user_days_spent_watching', 'access_rank', \\\n",
    "              'join_date', 'last_online', 'stats_mean_score', 'stats_rewatched', \\\n",
    "              'stats_episodes'],\n",
    "               axis=1, inplace=True)\n",
    "\n",
    "# cities_df.drop(['\\\"city\\\"', '\\\"lat\\\"', '\\\"lng\\\"', '\\\"iso2\\\"', '\\\"iso3\\\"' \\\n",
    "#                 '\\\"admin_name\\\"', '\\\"capital\\\"', '\\\"population\\\"', '\\\"id\\\"'],\n",
    "#                  axis=1, inplace=True)\n",
    "\n",
    "\n",
    "cities_df.drop(['city', 'lat', 'lng', 'iso2', 'iso3', \\\n",
    "                'admin_name', 'capital', 'population', 'id'],\n",
    "                 axis=1, inplace=True)\n",
    "cities_df.rename(columns={'city_ascii': 'city'}, inplace=True)\n",
    "cities_df['city'] = cities_df.city.str.lower()\n",
    "\n",
    "\n",
    "\n",
    "for column in cities_df[['city']]:\n",
    "    column_obj = cities_df[column]\n",
    "    print(column_obj.values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# drop all N/A values from the data frames\n",
    "anime_df.dropna(inplace=True)\n",
    "user_df.dropna(inplace=True)\n",
    "\n",
    "# fix broken apostrophes across the entire dataframe\n",
    "# anime_df.replace('&#039;', '\\'', inplace=True)\n",
    "anime_df['title'] = anime_df['title'].str.replace('&#039;', '\\'')\n",
    "\n",
    "# clean birth_date column so that it represents age as a number\n",
    "user_df['age'] = user_df['birth_date'].apply(calculate_age)\n",
    "user_df.drop('birth_date', axis=1, inplace=True)\n",
    "\n",
    "# clean location column so that it only list country\n",
    "# gc = geonamescache.GeonamesCache()\n",
    "# countries = gc.get_countries()\n",
    "# print(countries)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# remove animes that have not yet aired since they don't have scoring data\n",
    "# anime_df = anime_df[~anime_df['status'].isin(['Not yet aired'])]\n",
    "\n",
    "# remove NSFW content\n",
    "# anime_df = anime_df[~anime_df['genre'].astype(str).str.contains('Hentai')]\n",
    "\n",
    "# convert genres to a list\n",
    "# anime_df['genre'] = anime_df.genre.str.split(',')\n",
    "\n",
    "# write cleaned data frames to csv files\n",
    "# anime_df.to_csv('anime.csv', index=False)\n",
    "# user_df.to_csv('user.csv', index=False)\n",
    "\n",
    "#print('anime_df Shape:', anime_df.shape)\n",
    "#anime_df.head()\n",
    "#anime_df.isna().sum()\n",
    "\n",
    "#print('user_df Shape:', user_df.shape)\n",
    "#user_df.head()\n",
    "# user_df.isna().sum()\n",
    "\n",
    "# print('user_mal_df Shape:', user_mal_df.shape)\n",
    "# user_mal_df.head()\n",
    "# user_mal_df.isna().sum()\n",
    "\n",
    "# define chunk size for user_mal_data since the file is too large\n",
    "# my_chunk = 10**5\n",
    "# first_chunk = True\n",
    "# for chunk in pd.read_csv(user_mal_data, na_values=idntfrs,\n",
    "#                          chunksize=my_chunk, iterator=True):\n",
    "#     user_mal_df = chunk\n",
    "#     user_mal_df.drop(['my_watched_episodes', 'my_status', 'my_rewatching', \\\n",
    "#                       'my_rewatching_ep', 'my_last_updated', 'my_tags', \\\n",
    "#                       'my_start_date', 'my_finish_date'],\n",
    "#                       axis=1, inplace=True)\n",
    "#     user_mal_df.dropna(inplace=True)\n",
    "#     if first_chunk:   \n",
    "#         user_mal_df.to_csv('user_mal.csv', mode='w', header=True, index=False)\n",
    "#         first_chunk = False\n",
    "#     else:\n",
    "#         user_mal_df.to_csv('user_mal.csv', mode='a', header=False, index=False)\n",
    "\n",
    "\n",
    "print('cities_df Shape:', cities_df.shape)\n",
    "cities_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "anime_recommender.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ECE143",
   "language": "python",
   "name": "ece143"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
